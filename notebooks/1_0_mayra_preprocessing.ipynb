{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/77/63/a9fa76de8dffe7455304c4ed635be4aa9c0bacef6e0633d87d5f54530c5c/tensorflow-1.13.1-cp36-cp36m-manylinux1_x86_64.whl (92.5MB)\n",
      "\u001b[K    100% |████████████████████████████████| 92.5MB 49kB/s eta 0:00:011    13% |████▍                           | 12.6MB 4.3MB/s eta 0:00:19    14% |████▌                           | 13.0MB 3.0MB/s eta 0:00:27    67% |█████████████████████▋          | 62.4MB 2.3MB/s eta 0:00:13\n",
      "\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /home/danielmarx/.local/lib/python3.6/site-packages (from tensorflow) (0.6.2)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /home/danielmarx/.local/lib/python3.6/site-packages (from tensorflow) (1.14.5)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /home/danielmarx/anaconda3/lib/python3.6/site-packages (from tensorflow) (1.0.7)\n",
      "Requirement already satisfied: absl-py>=0.1.6 in /home/danielmarx/anaconda3/lib/python3.6/site-packages (from tensorflow) (0.7.1)\n",
      "Requirement already satisfied: wheel>=0.26 in /home/danielmarx/.local/lib/python3.6/site-packages (from tensorflow) (0.31.1)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /home/danielmarx/anaconda3/lib/python3.6/site-packages (from tensorflow) (1.0.9)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/danielmarx/.local/lib/python3.6/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: gast>=0.2.0 in /home/danielmarx/.local/lib/python3.6/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /home/danielmarx/.local/lib/python3.6/site-packages (from tensorflow) (1.12.1)\n",
      "Collecting tensorboard<1.14.0,>=1.13.0 (from tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/39/bdd75b08a6fba41f098b6cb091b9e8c7a80e1b4d679a581a0ccd17b10373/tensorboard-1.13.1-py3-none-any.whl (3.2MB)\n",
      "\u001b[K    100% |████████████████████████████████| 3.2MB 1.4MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: protobuf>=3.6.1 in /home/danielmarx/anaconda3/lib/python3.6/site-packages (from tensorflow) (3.7.1)\n",
      "Collecting tensorflow-estimator<1.14.0rc0,>=1.13.0 (from tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/48/13f49fc3fa0fdf916aa1419013bb8f2ad09674c275b4046d5ee669a46873/tensorflow_estimator-1.13.0-py2.py3-none-any.whl (367kB)\n",
      "\u001b[K    100% |████████████████████████████████| 368kB 3.6MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /home/danielmarx/.local/lib/python3.6/site-packages (from tensorflow) (1.11.0)\n",
      "Requirement already satisfied: h5py in /home/danielmarx/anaconda3/lib/python3.6/site-packages (from keras-applications>=1.0.6->tensorflow) (2.7.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/danielmarx/.local/lib/python3.6/site-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow) (0.14.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/danielmarx/.local/lib/python3.6/site-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow) (2.6.11)\n",
      "Requirement already satisfied: setuptools in /home/danielmarx/.local/lib/python3.6/site-packages (from protobuf>=3.6.1->tensorflow) (39.2.0)\n",
      "Collecting mock>=2.0.0 (from tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e6/35/f187bdf23be87092bd0f1200d43d23076cee4d0dec109f195173fd3ebc79/mock-2.0.0-py2.py3-none-any.whl (56kB)\n",
      "\u001b[K    100% |████████████████████████████████| 61kB 1.6MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting pbr>=0.11 (from mock>=2.0.0->tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/09/12fe9a14237a6b7e0ba3a8d6fcf254bf4b10ec56a0185f73d651145e9222/pbr-5.1.3-py2.py3-none-any.whl (107kB)\n",
      "\u001b[K    100% |████████████████████████████████| 112kB 3.5MB/s ta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: tensorboard, pbr, mock, tensorflow-estimator, tensorflow\n",
      "  Found existing installation: tensorboard 1.8.0\n",
      "    Uninstalling tensorboard-1.8.0:\n",
      "      Successfully uninstalled tensorboard-1.8.0\n",
      "Successfully installed mock-2.0.0 pbr-5.1.3 tensorboard-1.13.1 tensorflow-1.13.1 tensorflow-estimator-1.13.0\n"
     ]
    }
   ],
   "source": [
    "#Necessary to install keras\n",
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/10/aa32dad071ce52b5502266b5c659451cfd6ffcbf14e6c8c4f16c0ff5aaab/Keras-2.2.4-py2.py3-none-any.whl (312kB)\n",
      "\u001b[K    100% |████████████████████████████████| 317kB 1.3MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /home/danielmarx/anaconda3/lib/python3.6/site-packages (from keras) (1.0.9)\n",
      "Requirement already satisfied: six>=1.9.0 in /home/danielmarx/.local/lib/python3.6/site-packages (from keras) (1.11.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /home/danielmarx/anaconda3/lib/python3.6/site-packages (from keras) (1.0.7)\n",
      "Requirement already satisfied: pyyaml in /home/danielmarx/anaconda3/lib/python3.6/site-packages (from keras) (3.12)\n",
      "Requirement already satisfied: scipy>=0.14 in /home/danielmarx/anaconda3/lib/python3.6/site-packages (from keras) (1.1.0)\n",
      "Requirement already satisfied: h5py in /home/danielmarx/anaconda3/lib/python3.6/site-packages (from keras) (2.7.1)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /home/danielmarx/.local/lib/python3.6/site-packages (from keras) (1.14.5)\n",
      "Installing collected packages: keras\n",
      "Successfully installed keras-2.2.4\n"
     ]
    }
   ],
   "source": [
    "#Keras :)\n",
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "#from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the data using the Unnamed (probably id) as index\n",
    "url = 'https://s3.amazonaws.com/drivendata/data/4/public/81e8f2de-9915-4934-b9ae-9705685c9d50.csv'\n",
    "training = pd.read_csv(url, index_col='Unnamed: 0')\n",
    "\n",
    "labels = ['Function', 'Object_Type', 'Operating_Status', 'Position_Type', 'Pre_K', 'Reporting', \n",
    "          'Sharing', 'Student_Type', 'Use']\n",
    "\n",
    "numeric = ['FTE', 'Total']\n",
    "\n",
    "categoric = [ 'Facility_or_Department', 'Function_Description', \n",
    "            'Fund_Description', 'Job_Title_Description', 'Location_Description', \n",
    "            'Object_Description', 'Position_Extra', 'Program_Description', 'SubFund_Description', \n",
    "            'Sub_Object_Description', \n",
    "            'Text_1', 'Text_2', 'Text_3', 'Text_4']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning\n",
    "\n",
    "### Part 1: numeric data\n",
    "First of all, the numeric columns `FTE` and `Total` must be cleaned. The outliers will be treated as `NaN` values and imputation will be applied to the missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove inconsistent data\n",
    "training[training['FTE'] < 0] = np.nan\n",
    "training[training['Total'] < 0] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    125849.000000\n",
       "mean          0.427436\n",
       "std           0.573810\n",
       "min           0.000000\n",
       "25%           0.001078\n",
       "50%           0.133337\n",
       "75%           1.000000\n",
       "max          46.800000\n",
       "Name: FTE, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training['FTE'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Function</th>\n",
       "      <th>Use</th>\n",
       "      <th>Sharing</th>\n",
       "      <th>Reporting</th>\n",
       "      <th>Student_Type</th>\n",
       "      <th>Position_Type</th>\n",
       "      <th>Object_Type</th>\n",
       "      <th>Pre_K</th>\n",
       "      <th>Operating_Status</th>\n",
       "      <th>Object_Description</th>\n",
       "      <th>...</th>\n",
       "      <th>Sub_Object_Description</th>\n",
       "      <th>Location_Description</th>\n",
       "      <th>FTE</th>\n",
       "      <th>Function_Description</th>\n",
       "      <th>Facility_or_Department</th>\n",
       "      <th>Position_Extra</th>\n",
       "      <th>Total</th>\n",
       "      <th>Program_Description</th>\n",
       "      <th>Fund_Description</th>\n",
       "      <th>Text_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Function, Use, Sharing, Reporting, Student_Type, Position_Type, Object_Type, Pre_K, Operating_Status, Object_Description, Text_2, SubFund_Description, Job_Title_Description, Text_3, Text_4, Sub_Object_Description, Location_Description, FTE, Function_Description, Facility_or_Department, Position_Extra, Total, Program_Description, Fund_Description, Text_1]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 25 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training[training['FTE'] < 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    3.518450e+05\n",
       "mean     1.696423e+04\n",
       "std      3.402292e+05\n",
       "min      0.000000e+00\n",
       "25%      1.384847e+02\n",
       "50%      6.696800e+02\n",
       "75%      4.999610e+03\n",
       "max      1.297000e+08\n",
       "Name: Total, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training['Total'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Categoric data\n",
    "\n",
    "The strings must be normalized: symbols removed, all letters to lower case. Then, they can be transformed to numeric data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for category in categoric:\n",
    "    training[category] = training[category].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Facility_or_Department     176\n",
       "Function_Description       655\n",
       "Fund_Description           141\n",
       "Job_Title_Description     3455\n",
       "Location_Description       352\n",
       "Object_Description         570\n",
       "Position_Extra             580\n",
       "Program_Description        418\n",
       "SubFund_Description        267\n",
       "Sub_Object_Description     159\n",
       "Text_1                    1389\n",
       "Text_2                     279\n",
       "Text_3                      35\n",
       "Text_4                     240\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check if the unique values decrease\n",
    "training[categoric].nunique(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert columns\n",
    "training[categoric] = training[categoric].apply(lambda x: x.astype('object'), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 400277 entries, 134338 to 415831\n",
      "Data columns (total 14 columns):\n",
      "Facility_or_Department    53186 non-null object\n",
      "Function_Description      298676 non-null object\n",
      "Fund_Description          179157 non-null object\n",
      "Job_Title_Description     272317 non-null object\n",
      "Location_Description      155504 non-null object\n",
      "Object_Description        332143 non-null object\n",
      "Position_Extra            244180 non-null object\n",
      "Program_Description       280943 non-null object\n",
      "SubFund_Description       263731 non-null object\n",
      "Sub_Object_Description    70748 non-null object\n",
      "Text_1                    251891 non-null object\n",
      "Text_2                    87431 non-null object\n",
      "Text_3                    108613 non-null object\n",
      "Text_4                    53384 non-null object\n",
      "dtypes: object(14)\n",
      "memory usage: 45.8+ MB\n"
     ]
    }
   ],
   "source": [
    "training[categoric].info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before removing symbols, let's take a peek on some values and so we can detect the diferrences later\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "non-project                        True\n",
       "instruction                        True\n",
       "unalloc budgets/schools            True\n",
       "basic (fefp k-12)                 False\n",
       "employee retirement               False\n",
       "ela e-teaching sheltered eng      False\n",
       "Name: Function_Description, dtype: bool"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_functions = training['Function_Description'].value_counts(normalize=True) > 0.05\n",
    "some_functions.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove symbols\n",
    "'''for category in categoric:\n",
    "    training[category] = training[category].str.replace(r\"[&/\\)('\\\"-.,]\",\"\")'''\n",
    "vec = HashingVectorizer(token_pattern=\"[A-Za-z0-9]+(?=\\\\s+)\", ngram_range=(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "non-project                       0.191686\n",
       "instruction                       0.128882\n",
       "unalloc budgets/schools           0.055458\n",
       "basic (fefp k-12)                 0.044473\n",
       "employee retirement               0.043723\n",
       "ela e-teaching sheltered eng      0.021093\n",
       "Name: Function_Description, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training['Function_Description'].value_counts(normalize=True).head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "training[categoric] = training[categoric].fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training['Function_Description'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join all text items in a row that have a space in between\n",
    "text_data = training[categoric].apply(lambda x: \" \".join(x), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "134338      general fund teacher-elementary    kindergar...\n",
       "206341     rgn  gob  (blank)  contractor services undesi...\n",
       "326408      general purpose school tcher 2nd grade  pers...\n",
       "364634     unalloc budgets/schools  teacher, short term ...\n",
       "47683      non-project  teacher, secondary (high)   teac...\n",
       "229958                                                     \n",
       "417668      local fund   educational supplies and materi...\n",
       "126378     non-project  sub manager, food service  distr...\n",
       "275539     ela s - teaching spanish only  teacher, eleme...\n",
       "85262      unalloc budgets/schools  teacher,retrd shrt t...\n",
       "304569                                                     \n",
       "330504     instruction general fund   supplies  primary ...\n",
       "84272     position control pools  general purpose school...\n",
       "64760                                                      \n",
       "21870      basic (fefp k-12)              conversion cha...\n",
       "18698     all campus payroll instruction general operati...\n",
       "169454     basic (fefp k-12)              general fund  ...\n",
       "169914     security services general admin lieutenant co...\n",
       "189701     non-project  (blank)  electricity undesignate...\n",
       "43727                                                      \n",
       "5614       direction of support services - pupils * spec...\n",
       "291539     unalloc budgets/schools  teacher, short term ...\n",
       "307038     disadvantaged youth * title i - disadvantaged...\n",
       "27645      guidance services              conversion cha...\n",
       "126388      general purpose school   personal services -...\n",
       "14962       school federal projects tcher english (secon...\n",
       "84040                                                      \n",
       "61639      core matters  teacher, short term sub   emplo...\n",
       "266302     ela e-teaching sheltered eng  teacher, elemen...\n",
       "225768    transportation department transportation gener...\n",
       "                                ...                        \n",
       "333748     psychological services * general psychologist...\n",
       "292626    new construction department administration fac...\n",
       "343458     unalloc budgets/schools  teacher, super sub d...\n",
       "128261     special ed. - severe needs  teacher,spec ed c...\n",
       "186318     ela s - teaching spanish only  teacher, eleme...\n",
       "210652    teacher supply  school federal projects   pers...\n",
       "340354     title iii  ela  ela general assignment   empl...\n",
       "435205     read to achieve round three  teacher, element...\n",
       "174827     title i  ela general assignment   salaries of...\n",
       "277504                                                     \n",
       "248062    vocational curriculum development and instruct...\n",
       "70455      basic (fefp k-12)              conversion cha...\n",
       "203453     staff services                 extended learn...\n",
       "58170       school federal projects   personal services ...\n",
       "72072       general purpose school assistant principal -...\n",
       "68311      title ii-part a-teacher qualit  teacher, elem...\n",
       "225892     ela e-teaching sheltered eng  teacher, elemen...\n",
       "446383                                                     \n",
       "155111    transportation department transportation gener...\n",
       "278248     instruction general fund   supplies  primary ...\n",
       "397424     ns  gob  secondary spec ed para   additional/...\n",
       "375092      general purpose school   personal services -...\n",
       "220181    child nutrition food services (child nutrition...\n",
       "307423                                                     \n",
       "46691      title ii-part a-teacher qualit  teacher, elem...\n",
       "109283     inst staff training svcs       general fund  ...\n",
       "102430     title ii,d  teacher,retrd shrt term sub   sal...\n",
       "413949      schoolwide schools school liaison   parent/t...\n",
       "433672     non-project  library technician ii  ed resour...\n",
       "415831    instruction and curriculum instruction \"title ...\n",
       "Length: 400277, dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "hec = HashingVectorizer(token_pattern=\"[A-Za-z0-9]+(?=\\\\s+)\", norm=None, binary=False,\n",
    "                                                     ngram_range=(1,2))\n",
    "hashed_text = hec.fit_transform(text_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5221742 entries, 0 to 5221741\n",
      "Data columns (total 1 columns):\n",
      "0    float64\n",
      "dtypes: float64(1)\n",
      "memory usage: 39.8 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "hashed_df = pd.DataFrame(hashed_text.data)\n",
    "print(hashed_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.377964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.755929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.377964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.377964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.182574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.182574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.182574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.365148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.182574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.182574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.182574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.182574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.547723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.547723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.182574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.258199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.258199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.258199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.258199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.258199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.258199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.258199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-0.258199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.258199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-0.258199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.258199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.516398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.417029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-0.208514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.208514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5221712</th>\n",
       "      <td>-0.179605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5221713</th>\n",
       "      <td>-0.179605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5221714</th>\n",
       "      <td>0.538816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5221715</th>\n",
       "      <td>-0.251976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5221716</th>\n",
       "      <td>-0.251976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5221717</th>\n",
       "      <td>0.251976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5221718</th>\n",
       "      <td>-0.125988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5221719</th>\n",
       "      <td>-0.125988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5221720</th>\n",
       "      <td>-0.251976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5221721</th>\n",
       "      <td>0.251976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5221722</th>\n",
       "      <td>-0.125988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5221723</th>\n",
       "      <td>-0.125988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5221724</th>\n",
       "      <td>0.251976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5221725</th>\n",
       "      <td>0.251976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5221726</th>\n",
       "      <td>0.125988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5221727</th>\n",
       "      <td>-0.503953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5221728</th>\n",
       "      <td>-0.125988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5221729</th>\n",
       "      <td>0.125988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5221730</th>\n",
       "      <td>-0.125988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5221731</th>\n",
       "      <td>-0.125988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5221732</th>\n",
       "      <td>0.125988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5221733</th>\n",
       "      <td>0.125988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5221734</th>\n",
       "      <td>0.125988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5221735</th>\n",
       "      <td>-0.125988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5221736</th>\n",
       "      <td>-0.125988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5221737</th>\n",
       "      <td>-0.125988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5221738</th>\n",
       "      <td>0.125988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5221739</th>\n",
       "      <td>-0.125988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5221740</th>\n",
       "      <td>-0.125988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5221741</th>\n",
       "      <td>-0.125988</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5221742 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0\n",
       "0        0.377964\n",
       "1        0.755929\n",
       "2        0.377964\n",
       "3        0.377964\n",
       "4        0.182574\n",
       "5       -0.182574\n",
       "6       -0.182574\n",
       "7       -0.365148\n",
       "8        0.182574\n",
       "9        0.182574\n",
       "10       0.182574\n",
       "11      -0.182574\n",
       "12      -0.547723\n",
       "13       0.547723\n",
       "14       0.182574\n",
       "15       0.258199\n",
       "16       0.258199\n",
       "17      -0.258199\n",
       "18      -0.258199\n",
       "19      -0.258199\n",
       "20       0.258199\n",
       "21       0.258199\n",
       "22      -0.258199\n",
       "23       0.258199\n",
       "24      -0.258199\n",
       "25       0.258199\n",
       "26       0.516398\n",
       "27       0.417029\n",
       "28      -0.208514\n",
       "29       0.208514\n",
       "...           ...\n",
       "5221712 -0.179605\n",
       "5221713 -0.179605\n",
       "5221714  0.538816\n",
       "5221715 -0.251976\n",
       "5221716 -0.251976\n",
       "5221717  0.251976\n",
       "5221718 -0.125988\n",
       "5221719 -0.125988\n",
       "5221720 -0.251976\n",
       "5221721  0.251976\n",
       "5221722 -0.125988\n",
       "5221723 -0.125988\n",
       "5221724  0.251976\n",
       "5221725  0.251976\n",
       "5221726  0.125988\n",
       "5221727 -0.503953\n",
       "5221728 -0.125988\n",
       "5221729  0.125988\n",
       "5221730 -0.125988\n",
       "5221731 -0.125988\n",
       "5221732  0.125988\n",
       "5221733  0.125988\n",
       "5221734  0.125988\n",
       "5221735 -0.125988\n",
       "5221736 -0.125988\n",
       "5221737 -0.125988\n",
       "5221738  0.125988\n",
       "5221739 -0.125988\n",
       "5221740 -0.125988\n",
       "5221741 -0.125988\n",
       "\n",
       "[5221742 rows x 1 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hashed_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro to Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense\n",
    "from tensorflow.python.keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_data = training[numeric]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp = Imputer(missing_values='NaN', strategy='mean', axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danielmarx/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/home/danielmarx/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py:3141: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.loc._setitem_with_indexer((slice(None), indexer), value)\n",
      "/home/danielmarx/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py:3113: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_array(key, value)\n"
     ]
    }
   ],
   "source": [
    "#Simple imputations\n",
    "numeric_data[['FTE']] = imp.fit(numeric_data[['FTE']]).transform(numeric_data[['FTE']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danielmarx/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/home/danielmarx/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py:3141: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.loc._setitem_with_indexer((slice(None), indexer), value)\n",
      "/home/danielmarx/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py:3113: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_array(key, value)\n"
     ]
    }
   ],
   "source": [
    "numeric_data[['Total']] = imp.fit(numeric_data[['Total']]).transform(numeric_data[['Total']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 400277 entries, 134338 to 415831\n",
      "Data columns (total 2 columns):\n",
      "FTE      400277 non-null float64\n",
      "Total    400277 non-null float64\n",
      "dtypes: float64(2)\n",
      "memory usage: 19.2 MB\n"
     ]
    }
   ],
   "source": [
    "numeric_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FTE</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>400277.000000</td>\n",
       "      <td>4.002770e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.427436</td>\n",
       "      <td>1.696423e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.321745</td>\n",
       "      <td>3.189825e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.427436</td>\n",
       "      <td>1.747800e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.427436</td>\n",
       "      <td>1.046583e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.427436</td>\n",
       "      <td>1.696423e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>46.800000</td>\n",
       "      <td>1.297000e+08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 FTE         Total\n",
       "count  400277.000000  4.002770e+05\n",
       "mean        0.427436  1.696423e+04\n",
       "std         0.321745  3.189825e+05\n",
       "min         0.000000  0.000000e+00\n",
       "25%         0.427436  1.747800e+02\n",
       "50%         0.427436  1.046583e+03\n",
       "75%         0.427436  1.696423e+04\n",
       "max        46.800000  1.297000e+08"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dummies = pd.get_dummies(training[labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Function_Aides Compensation</th>\n",
       "      <th>Function_Career &amp; Academic Counseling</th>\n",
       "      <th>Function_Communications</th>\n",
       "      <th>Function_Curriculum Development</th>\n",
       "      <th>Function_Data Processing &amp; Information Services</th>\n",
       "      <th>Function_Development &amp; Fundraising</th>\n",
       "      <th>Function_Enrichment</th>\n",
       "      <th>Function_Extended Time &amp; Tutoring</th>\n",
       "      <th>Function_Facilities &amp; Maintenance</th>\n",
       "      <th>Function_Facilities Planning</th>\n",
       "      <th>...</th>\n",
       "      <th>Student_Type_Special Education</th>\n",
       "      <th>Student_Type_Unspecified</th>\n",
       "      <th>Use_Business Services</th>\n",
       "      <th>Use_ISPD</th>\n",
       "      <th>Use_Instruction</th>\n",
       "      <th>Use_Leadership</th>\n",
       "      <th>Use_NO_LABEL</th>\n",
       "      <th>Use_O&amp;M</th>\n",
       "      <th>Use_Pupil Services &amp; Enrichment</th>\n",
       "      <th>Use_Untracked Budget Set-Aside</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>134338</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206341</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326408</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364634</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47683</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 104 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Function_Aides Compensation  Function_Career & Academic Counseling  \\\n",
       "134338                            0                                      0   \n",
       "206341                            0                                      0   \n",
       "326408                            0                                      0   \n",
       "364634                            0                                      0   \n",
       "47683                             0                                      0   \n",
       "\n",
       "        Function_Communications  Function_Curriculum Development  \\\n",
       "134338                        0                                0   \n",
       "206341                        0                                0   \n",
       "326408                        0                                0   \n",
       "364634                        0                                0   \n",
       "47683                         0                                0   \n",
       "\n",
       "        Function_Data Processing & Information Services  \\\n",
       "134338                                                0   \n",
       "206341                                                0   \n",
       "326408                                                0   \n",
       "364634                                                0   \n",
       "47683                                                 0   \n",
       "\n",
       "        Function_Development & Fundraising  Function_Enrichment  \\\n",
       "134338                                   0                    0   \n",
       "206341                                   0                    0   \n",
       "326408                                   0                    0   \n",
       "364634                                   0                    0   \n",
       "47683                                    0                    0   \n",
       "\n",
       "        Function_Extended Time & Tutoring  Function_Facilities & Maintenance  \\\n",
       "134338                                  0                                  0   \n",
       "206341                                  0                                  0   \n",
       "326408                                  0                                  0   \n",
       "364634                                  0                                  0   \n",
       "47683                                   0                                  0   \n",
       "\n",
       "        Function_Facilities Planning               ...                \\\n",
       "134338                             0               ...                 \n",
       "206341                             0               ...                 \n",
       "326408                             0               ...                 \n",
       "364634                             0               ...                 \n",
       "47683                              0               ...                 \n",
       "\n",
       "        Student_Type_Special Education  Student_Type_Unspecified  \\\n",
       "134338                               0                         0   \n",
       "206341                               0                         0   \n",
       "326408                               0                         1   \n",
       "364634                               0                         1   \n",
       "47683                                0                         1   \n",
       "\n",
       "        Use_Business Services  Use_ISPD  Use_Instruction  Use_Leadership  \\\n",
       "134338                      0         0                1               0   \n",
       "206341                      0         0                0               0   \n",
       "326408                      0         0                1               0   \n",
       "364634                      0         0                1               0   \n",
       "47683                       0         0                1               0   \n",
       "\n",
       "        Use_NO_LABEL  Use_O&M  Use_Pupil Services & Enrichment  \\\n",
       "134338             0        0                                0   \n",
       "206341             1        0                                0   \n",
       "326408             0        0                                0   \n",
       "364634             0        0                                0   \n",
       "47683              0        0                                0   \n",
       "\n",
       "        Use_Untracked Budget Set-Aside  \n",
       "134338                               0  \n",
       "206341                               0  \n",
       "326408                               0  \n",
       "364634                               0  \n",
       "47683                                0  \n",
       "\n",
       "[5 rows x 104 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dummies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 400277 entries, 134338 to 415831\n",
      "Columns: 104 entries, Function_Aides Compensation to Use_Untracked Budget Set-Aside\n",
      "dtypes: uint8(104)\n",
      "memory usage: 52.8 MB\n"
     ]
    }
   ],
   "source": [
    "df_dummies.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(numeric_data,\n",
    "                                                    df_dummies,\n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FTE</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>444691</th>\n",
       "      <td>0.427436</td>\n",
       "      <td>218.450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250816</th>\n",
       "      <td>0.427436</td>\n",
       "      <td>3126.332668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393405</th>\n",
       "      <td>0.427436</td>\n",
       "      <td>674.710000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299533</th>\n",
       "      <td>0.427436</td>\n",
       "      <td>286.688429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357445</th>\n",
       "      <td>0.427436</td>\n",
       "      <td>221.843840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67965</th>\n",
       "      <td>0.427436</td>\n",
       "      <td>16964.228336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327481</th>\n",
       "      <td>0.427436</td>\n",
       "      <td>775.291920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81419</th>\n",
       "      <td>0.427436</td>\n",
       "      <td>16964.228336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397760</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>18309.289661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426528</th>\n",
       "      <td>0.427436</td>\n",
       "      <td>525.670000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65311</th>\n",
       "      <td>0.427436</td>\n",
       "      <td>3782.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434624</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>54274.300409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77089</th>\n",
       "      <td>0.507000</td>\n",
       "      <td>7137.062000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50530</th>\n",
       "      <td>0.427436</td>\n",
       "      <td>28.940000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407634</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>36071.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203082</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>53985.199608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57218</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>38.040000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22690</th>\n",
       "      <td>0.427436</td>\n",
       "      <td>75.700960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420630</th>\n",
       "      <td>0.427436</td>\n",
       "      <td>8.870000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387203</th>\n",
       "      <td>0.427436</td>\n",
       "      <td>4634.460000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229587</th>\n",
       "      <td>0.427436</td>\n",
       "      <td>76.990000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273271</th>\n",
       "      <td>0.427436</td>\n",
       "      <td>8.630000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366189</th>\n",
       "      <td>0.427436</td>\n",
       "      <td>93.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347828</th>\n",
       "      <td>0.427436</td>\n",
       "      <td>16964.228336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381948</th>\n",
       "      <td>0.427436</td>\n",
       "      <td>1714.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156910</th>\n",
       "      <td>0.004310</td>\n",
       "      <td>110.087938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172542</th>\n",
       "      <td>0.427436</td>\n",
       "      <td>1600.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194027</th>\n",
       "      <td>0.427436</td>\n",
       "      <td>15.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285169</th>\n",
       "      <td>0.427436</td>\n",
       "      <td>1015.850000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231037</th>\n",
       "      <td>0.427436</td>\n",
       "      <td>16964.228336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268353</th>\n",
       "      <td>0.427436</td>\n",
       "      <td>252.170000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166586</th>\n",
       "      <td>0.427436</td>\n",
       "      <td>7901.905040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303288</th>\n",
       "      <td>0.427436</td>\n",
       "      <td>16964.228336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120032</th>\n",
       "      <td>0.427436</td>\n",
       "      <td>5229.730000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280843</th>\n",
       "      <td>0.427436</td>\n",
       "      <td>16964.228336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78197</th>\n",
       "      <td>0.427436</td>\n",
       "      <td>676.980000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168315</th>\n",
       "      <td>0.427436</td>\n",
       "      <td>768.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237943</th>\n",
       "      <td>0.427436</td>\n",
       "      <td>293505.370000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54728</th>\n",
       "      <td>0.427436</td>\n",
       "      <td>538.806080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417064</th>\n",
       "      <td>0.427436</td>\n",
       "      <td>169.757920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38306</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>25419.830000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185167</th>\n",
       "      <td>0.427436</td>\n",
       "      <td>244.910000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331144</th>\n",
       "      <td>0.427436</td>\n",
       "      <td>7.630000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257773</th>\n",
       "      <td>0.427436</td>\n",
       "      <td>504.130000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64708</th>\n",
       "      <td>0.427436</td>\n",
       "      <td>103452.880000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222589</th>\n",
       "      <td>0.427436</td>\n",
       "      <td>184.468000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251393</th>\n",
       "      <td>0.427436</td>\n",
       "      <td>60.140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119697</th>\n",
       "      <td>0.008621</td>\n",
       "      <td>218.925877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166328</th>\n",
       "      <td>0.427436</td>\n",
       "      <td>4847.170000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352362</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>43524.371087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144415</th>\n",
       "      <td>0.427436</td>\n",
       "      <td>165.540000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259970</th>\n",
       "      <td>0.427436</td>\n",
       "      <td>16964.228336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206670</th>\n",
       "      <td>0.004310</td>\n",
       "      <td>128.894985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221805</th>\n",
       "      <td>0.427436</td>\n",
       "      <td>433.498720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337333</th>\n",
       "      <td>0.427436</td>\n",
       "      <td>242.624378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355968</th>\n",
       "      <td>0.427436</td>\n",
       "      <td>30863.030000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63793</th>\n",
       "      <td>0.427436</td>\n",
       "      <td>249.740000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117220</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>104603.717870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62296</th>\n",
       "      <td>0.427436</td>\n",
       "      <td>16964.228336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172004</th>\n",
       "      <td>0.427436</td>\n",
       "      <td>10205.560000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>320221 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             FTE          Total\n",
       "444691  0.427436     218.450000\n",
       "250816  0.427436    3126.332668\n",
       "393405  0.427436     674.710000\n",
       "299533  0.427436     286.688429\n",
       "357445  0.427436     221.843840\n",
       "67965   0.427436   16964.228336\n",
       "327481  0.427436     775.291920\n",
       "81419   0.427436   16964.228336\n",
       "397760  1.000000   18309.289661\n",
       "426528  0.427436     525.670000\n",
       "65311   0.427436    3782.950000\n",
       "434624  1.000000   54274.300409\n",
       "77089   0.507000    7137.062000\n",
       "50530   0.427436      28.940000\n",
       "407634  1.000000   36071.050000\n",
       "203082  1.000000   53985.199608\n",
       "57218   0.000000      38.040000\n",
       "22690   0.427436      75.700960\n",
       "420630  0.427436       8.870000\n",
       "387203  0.427436    4634.460000\n",
       "229587  0.427436      76.990000\n",
       "273271  0.427436       8.630000\n",
       "366189  0.427436      93.300000\n",
       "347828  0.427436   16964.228336\n",
       "381948  0.427436    1714.010000\n",
       "156910  0.004310     110.087938\n",
       "172542  0.427436    1600.550000\n",
       "194027  0.427436      15.700000\n",
       "285169  0.427436    1015.850000\n",
       "231037  0.427436   16964.228336\n",
       "...          ...            ...\n",
       "268353  0.427436     252.170000\n",
       "166586  0.427436    7901.905040\n",
       "303288  0.427436   16964.228336\n",
       "120032  0.427436    5229.730000\n",
       "280843  0.427436   16964.228336\n",
       "78197   0.427436     676.980000\n",
       "168315  0.427436     768.650000\n",
       "237943  0.427436  293505.370000\n",
       "54728   0.427436     538.806080\n",
       "417064  0.427436     169.757920\n",
       "38306   1.000000   25419.830000\n",
       "185167  0.427436     244.910000\n",
       "331144  0.427436       7.630000\n",
       "257773  0.427436     504.130000\n",
       "64708   0.427436  103452.880000\n",
       "222589  0.427436     184.468000\n",
       "251393  0.427436      60.140000\n",
       "119697  0.008621     218.925877\n",
       "166328  0.427436    4847.170000\n",
       "352362  1.000000   43524.371087\n",
       "144415  0.427436     165.540000\n",
       "259970  0.427436   16964.228336\n",
       "206670  0.004310     128.894985\n",
       "221805  0.427436     433.498720\n",
       "337333  0.427436     242.624378\n",
       "355968  0.427436   30863.030000\n",
       "63793   0.427436     249.740000\n",
       "117220  1.000000  104603.717870\n",
       "62296   0.427436   16964.228336\n",
       "172004  0.427436   10205.560000\n",
       "\n",
       "[320221 rows x 2 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-4.88841566e-04, -4.97323999e-02],\n",
       "       [-4.88841566e-04, -4.12037278e-02],\n",
       "       [-4.88841566e-04, -4.83942125e-02],\n",
       "       ...,\n",
       "       [ 1.72325784e+00,  2.56424286e-01],\n",
       "       [-4.88841566e-04, -6.17882959e-04],\n",
       "       [-4.88841566e-04, -2.04407137e-02]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(32, activation='relu', input_dim=100))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Generate dummy data\n",
    "import numpy as np\n",
    "data = np.random.random((1000, 100))\n",
    "labels = np.random.randint(10, size=(1000, 1))\n",
    "\n",
    "# Convert labels to categorical one-hot encoding\n",
    "one_hot_labels = keras.utils.to_categorical(labels, num_classes=10)\n",
    "\n",
    "# Train the model, iterating on the data in batches of 32 samples\n",
    "model.fit(data, one_hot_labels, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "#seed = 7\n",
    "#np.random.seed(seed)\n",
    "\n",
    "# Initialising the ANN\n",
    "classifier = Sequential()\n",
    "\n",
    "# Adding the input layer and the first hidden, the hidden layer number is (104 + 2)/2\n",
    "classifier.add(Dense(53, activation = 'relu', input_dim = 2))\n",
    "\n",
    "# Adding the output layer\n",
    "classifier.add(Dense(104, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'read_only_collections'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-81-2edb7d50cab0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m classifier.compile(optimizer= \"rmsprop\",\n\u001b[1;32m      3\u001b[0m               \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m               metrics=['accuracy'])\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Fitting the ANN to the Training set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, optimizer, loss, metrics, loss_weights, sample_weight_mode, weighted_metrics, target_tensors, distribute, **kwargs)\u001b[0m\n\u001b[1;32m    428\u001b[0m           \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m           \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m           \u001b[0mloss_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_functions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m           \u001b[0msample_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m           \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_prepare_total_loss\u001b[0;34m(self, skip_target_indices, masks)\u001b[0m\n\u001b[1;32m   1684\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1685\u001b[0m       \u001b[0mmetrics_tensors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compile_stateful_metrics_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1686\u001b[0;31m     \u001b[0mmetrics_tensors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_all_metrics_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1687\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmetrics_tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/losses.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, y_true, y_pred, sample_weight)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \"\"\"Instantiates a `Loss` from its config (output of `get_config()`).\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m     \u001b[0mArgs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m         \u001b[0mconfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOutput\u001b[0m \u001b[0mof\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/utils/losses_utils.py\u001b[0m in \u001b[0;36mcompute_weighted_loss\u001b[0;34m(losses, sample_weight, reduction, name)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/weights_broadcast_ops.py\u001b[0m in \u001b[0;36mbroadcast_weights\u001b[0;34m(weights, values)\u001b[0m\n\u001b[1;32m    165\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massert_broadcastable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m       return math_ops.multiply(\n\u001b[1;32m    169\u001b[0m           weights, array_ops.ones_like(values), name=scope)\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/weights_broadcast_ops.py\u001b[0m in \u001b[0;36massert_broadcastable\u001b[0;34m(weights, values)\u001b[0m\n\u001b[1;32m    130\u001b[0m         lambda: _has_valid_nonscalar_shape(  # pylint: disable=g-long-lambda\n\u001b[1;32m    131\u001b[0m             weights_rank, weights_shape, values_rank, values_shape),\n\u001b[0;32m--> 132\u001b[0;31m         name=\"is_valid_shape\")\n\u001b[0m\u001b[1;32m    133\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcontrol_flow_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAssert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_valid_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    505\u001b[0m                 \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m                 instructions)\n\u001b[0;32m--> 507\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m     doc = _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mcond\u001b[0;34m(pred, true_fn, false_fn, strict, name, fn1, fn2)\u001b[0m\n\u001b[1;32m   1916\u001b[0m         \u001b[0mreal_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexternal_val\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1917\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mreal_val\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1919\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_BuildCondTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1920\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOperation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/cond_v2.py\u001b[0m in \u001b[0;36mcond_v2\u001b[0;34m(pred, true_fn, false_fn, name)\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0mtrue_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         func_graph=util.CondBranchFuncGraph(\n\u001b[0;32m---> 71\u001b[0;31m             true_name, read_only_collections=False),\n\u001b[0m\u001b[1;32m     72\u001b[0m         \u001b[0madd_control_dependencies\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0madd_control_dependencies\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         op_return_value=pred)\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'read_only_collections'"
     ]
    }
   ],
   "source": [
    "# Compiling the ANN\n",
    "classifier.compile(optimizer= \"rmsprop\",\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Fitting the ANN to the Training set\n",
    "#classifier.fit(X_train, y_train, batch_size = 10, epochs = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making predictions and evaluating the model\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# We now consider any prediction >0.5 as 1 and <=0.5 as 0\n",
    "y_pred = np.round_(y_pred,0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
