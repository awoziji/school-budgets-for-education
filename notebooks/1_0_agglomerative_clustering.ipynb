{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1_0_agglomerative_clustering.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PqCFyeQ_sW8W",
        "colab_type": "text"
      },
      "source": [
        "## Import libraries and load files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUiEzprZfYSG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "\n",
        "def get_available_gpus():\n",
        "    local_device_protos = device_lib.list_local_devices()\n",
        "    return [x.name for x in local_device_protos if x.device_type == 'GPU']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8T4LH03farA",
        "colab_type": "code",
        "outputId": "3055bfc2-86bc-49c3-d265-cbeaf6b77837",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "get_available_gpus()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/device:GPU:0']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZsrhZTaxKEQj",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import HashingVectorizer\n",
        "from sklearn.pipeline import FeatureUnion, Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import FunctionTransformer, LabelEncoder\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.metrics import SCORERS\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from warnings import warn\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from sklearn.metrics import silhouette_samples, silhouette_score, davies_bouldin_score, adjusted_rand_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AhRExPjIKk0Z",
        "colab": {}
      },
      "source": [
        "#Read the data using the Unnamed (probably id) as index\n",
        "url = 'https://s3.amazonaws.com/drivendata/data/4/public/81e8f2de-9915-4934-b9ae-9705685c9d50.csv'\n",
        "#url = '../src/data/raw/training.csv'\n",
        "training = pd.read_csv(url, index_col='Unnamed: 0')\n",
        "\n",
        "labels = ['Function', 'Object_Type', 'Operating_Status', 'Position_Type', 'Pre_K', 'Reporting', \n",
        "          'Sharing', 'Student_Type', 'Use']\n",
        "\n",
        "numeric = ['FTE', 'Total']\n",
        "\n",
        "categoric = [ 'Facility_or_Department', 'Function_Description', \n",
        "            'Fund_Description', 'Job_Title_Description', 'Location_Description', \n",
        "            'Object_Description', 'Position_Extra', 'Program_Description', 'SubFund_Description', \n",
        "            'Sub_Object_Description', \n",
        "            'Text_1', 'Text_2', 'Text_3', 'Text_4']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Vpbmr1_LJ9RX"
      },
      "source": [
        "### FunctionTransformers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gd4Nfma5J0n0",
        "colab": {}
      },
      "source": [
        "# Define combine_text_columns()\n",
        "def combine_text_columns(data_frame):\n",
        "    \"\"\" converts all text in each row of data_frame to single vector \"\"\"\n",
        "    \n",
        "    # Drop non-text columns that are in the df\n",
        "    text_data = data_frame[categoric].copy()\n",
        "    \n",
        "    # Replace nans with blanks\n",
        "    text_data.fillna(\"\", inplace=True)\n",
        "    \n",
        "    for category in categoric:\n",
        "      training.loc[:,category] = training[category].str.lower()\n",
        "    \n",
        "    \n",
        "    # Join all text items in a row that have a space in between\n",
        "    return text_data.apply(lambda x: \" \".join(x), axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zKQx45RdKR4o",
        "colab": {}
      },
      "source": [
        "groupped_FTE = training[['FTE', 'Object_Type']].groupby(by='Object_Type')\n",
        "groupped_total = training[['Total', 'Object_Type']].groupby(by='Object_Type')\n",
        "# Define combine_numeric_columns()\n",
        "def combine_numeric_columns(data_frame, groupped_FTE=groupped_FTE, groupped_total=groupped_total):\n",
        "    \"\"\" process all the numeric data \"\"\"\n",
        "    \n",
        "    # Drop non-numeric columns that are in the df\n",
        "    data = data_frame[numeric].copy()\n",
        "    \n",
        "    #Remove inconsistent data\n",
        "    data.loc[(data[numeric[0]] < 0) | (data[numeric[0]] > 1), numeric[0]] = np.nan\n",
        "    data.loc[(data[numeric[1]] < 0), numeric[1]] = np.nan\n",
        "    \n",
        "    #Impute the missing data with the median from each class\n",
        "    for group in groupped_FTE.median().index:\n",
        "      indexes_FTE = groupped_FTE.get_group(group).index.values\n",
        "      indexes_total = groupped_total.get_group(group).index.values\n",
        "      data.loc[ data.FTE.isnull() & np.isin(data.index.values,indexes_FTE), 'FTE'] = groupped_FTE.median().loc[group, \"FTE\"]\n",
        "      data.loc[ data.Total.isnull() & np.isin(data.index.values,indexes_total), 'Total'] = groupped_total.median().loc[group,\"Total\"]\n",
        "      \n",
        "    return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "k1BlfwlPKWnC",
        "colab": {}
      },
      "source": [
        "# Preprocess the text data: get_text_data\n",
        "get_text_data = FunctionTransformer(combine_text_columns, validate=False)\n",
        "\n",
        "# Preprocess the numeric data: get_numeric_data\n",
        "get_numeric_data = FunctionTransformer(combine_numeric_columns, validate=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kP0v3M2_5DH1",
        "colab": {}
      },
      "source": [
        "# Recover the targets and split the data\n",
        "y = pd.get_dummies(training['Object_Type'])\n",
        "\n",
        "X = training.drop(columns=labels)\n",
        "\n",
        "# rus = RandomUnderSampler(random_state=0)\n",
        "# X_resampled, y_resampled = rus.fit_resample(X, y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yfHLD6La5GAY"
      },
      "source": [
        "### Pipeline\n",
        "\n",
        "Apply the transformations on numeric and categorica data. Neither dimension reduction or standard scaler are used."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fF2c4SLDhTGI",
        "colab": {}
      },
      "source": [
        "pl = Pipeline([\n",
        "        ('union', FeatureUnion(\n",
        "            transformer_list = [\n",
        "                ('numeric_features', Pipeline([\n",
        "                    ('selector', get_numeric_data),\n",
        "                    ('imp', SimpleImputer())\n",
        "                ])),\n",
        "                ('text_features', Pipeline([\n",
        "                    ('selector', get_text_data),\n",
        "                    ('vectorizer',HashingVectorizer(token_pattern=\"[A-Za-z0-9]+(?=\\\\s+)\", \n",
        "                                                    norm=None, \n",
        "                                                    binary=False,\n",
        "                                                    ngram_range=(1,2)) \n",
        "                    )\n",
        "                ]))\n",
        "             ]\n",
        "        )),\n",
        "        ('reduce_dim', TruncatedSVD(n_components = 100)),\n",
        "        # ('clf', AgglomerativeClustering(memory='mycachedir', \n",
        "        #                     compute_full_tree=True, n_clusters=3))\n",
        "        \n",
        "    ])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8i9c6MQV6xoE"
      },
      "source": [
        "Applying the steps, we got a sparse matrix with 1048578 features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMF0sGuqHAmm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_X= pl.fit_transform(X, y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EjyoWAxvIHDN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rus = RandomUnderSampler()\n",
        "X_resampled, y_resampled = rus.fit_resample(data_X, y.values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Co8UpknaLjSR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3431f199-a436-4ad3-cc56-aa74192460c1"
      },
      "source": [
        "X_resampled.shape"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(35420, 100)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVDALl0YLmjd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d31f97e2-9512-409e-c500-679abd44a8af"
      },
      "source": [
        "y_resampled.shape"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(35420, 11)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bjKicnDBv4B0",
        "colab_type": "text"
      },
      "source": [
        "## Training\n",
        "The model is trained and tested using the number of groups varying between 2 and 20. As the agglomerative clustering method is deterministic, the model is fitted only one time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "osCoNLbMHrLR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "results = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "09avNYUp4zw5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 921
        },
        "outputId": "5f6dcd0e-827a-4348-9b18-0b712f7605f8"
      },
      "source": [
        "for k in range(2, 21):\n",
        "  agg = AgglomerativeClustering(memory='mycachedir', \n",
        "                             compute_full_tree=True, n_clusters=k)\n",
        "  with tf.device('/gpu:0'):\n",
        "    #fit model to data\n",
        "    cluster_labels = agg.fit_predict(X_resampled)\n",
        "    \n",
        "  # The silhouette_score gives the average value for all the samples.\n",
        "  # This gives a perspective into the density and separation of the formed\n",
        "  # clusters\n",
        "  silhouette_avg = silhouette_score(X_resampled, cluster_labels)\n",
        "  print(\"For n_clusters =\", k,\n",
        "        \"The average silhouette_score is :\", silhouette_avg)\n",
        "  \n",
        "  db_avg = davies_bouldin_score(X_resampled, cluster_labels)\n",
        "  print(\"For n_clusters =\", k,\n",
        "        \"The average db_score is :\", db_avg)\n",
        "  \n",
        "  # Append the results\n",
        "  results.append({'k':k, 'silhouette': silhouette_avg,\n",
        "                 'db': db_avg})"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "For n_clusters = 2 The average silhouette_score is : 0.9985316325554371\n",
            "For n_clusters = 2 The average db_score is : 0.10570938565578004\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/unsupervised.py:342: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  score = (intra_dists[:, None] + intra_dists) / centroid_distances\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "For n_clusters = 3 The average silhouette_score is : 0.9892538125423193\n",
            "For n_clusters = 3 The average db_score is : 0.47954795284588975\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/unsupervised.py:342: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  score = (intra_dists[:, None] + intra_dists) / centroid_distances\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "For n_clusters = 4 The average silhouette_score is : 0.987351984210137\n",
            "For n_clusters = 4 The average db_score is : 0.402396162915278\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/unsupervised.py:342: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  score = (intra_dists[:, None] + intra_dists) / centroid_distances\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "For n_clusters = 5 The average silhouette_score is : 0.9821865245924213\n",
            "For n_clusters = 5 The average db_score is : 0.36551950315862924\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/unsupervised.py:342: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  score = (intra_dists[:, None] + intra_dists) / centroid_distances\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "For n_clusters = 6 The average silhouette_score is : 0.9465753249478333\n",
            "For n_clusters = 6 The average db_score is : 0.40052222202320226\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/unsupervised.py:342: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  score = (intra_dists[:, None] + intra_dists) / centroid_distances\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "For n_clusters = 7 The average silhouette_score is : 0.9465603429622959\n",
            "For n_clusters = 7 The average db_score is : 0.44509160921938956\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/unsupervised.py:342: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  score = (intra_dists[:, None] + intra_dists) / centroid_distances\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "For n_clusters = 8 The average silhouette_score is : 0.8922431116937046\n",
            "For n_clusters = 8 The average db_score is : 0.4655814409064645\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/unsupervised.py:342: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  score = (intra_dists[:, None] + intra_dists) / centroid_distances\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "For n_clusters = 9 The average silhouette_score is : 0.892207370368799\n",
            "For n_clusters = 9 The average db_score is : 0.4036978909153579\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/unsupervised.py:342: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  score = (intra_dists[:, None] + intra_dists) / centroid_distances\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/unsupervised.py:342: RuntimeWarning: invalid value encountered in true_divide\n",
            "  score = (intra_dists[:, None] + intra_dists) / centroid_distances\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "For n_clusters = 10 The average silhouette_score is : 0.8921634205486239\n",
            "For n_clusters = 10 The average db_score is : 0.41466608304339714\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/unsupervised.py:342: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  score = (intra_dists[:, None] + intra_dists) / centroid_distances\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/unsupervised.py:342: RuntimeWarning: invalid value encountered in true_divide\n",
            "  score = (intra_dists[:, None] + intra_dists) / centroid_distances\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "For n_clusters = 11 The average silhouette_score is : 0.8921679358518021\n",
            "For n_clusters = 11 The average db_score is : 0.3539080269586909\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/unsupervised.py:342: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  score = (intra_dists[:, None] + intra_dists) / centroid_distances\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/unsupervised.py:342: RuntimeWarning: invalid value encountered in true_divide\n",
            "  score = (intra_dists[:, None] + intra_dists) / centroid_distances\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "For n_clusters = 12 The average silhouette_score is : 0.8922819657298096\n",
            "For n_clusters = 12 The average db_score is : 0.3589793761030178\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/unsupervised.py:342: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  score = (intra_dists[:, None] + intra_dists) / centroid_distances\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/unsupervised.py:342: RuntimeWarning: invalid value encountered in true_divide\n",
            "  score = (intra_dists[:, None] + intra_dists) / centroid_distances\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZFv7EeAzgNn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "results"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMM4z1go0R01",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}